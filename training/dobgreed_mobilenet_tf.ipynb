{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==1.9.0 Keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install graphviz -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python import keras as tf_keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "\n",
    "import numpy as np\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.python import keras\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "#from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "#from tensorflow.python.keras import models\n",
    "#from tensorflow.python.keras import layers\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import vis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from tensorflow.python.keras.applications import imagenet_utils\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  valid\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"data/train\"\n",
    "valid_folder = \"data/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE=224\n",
    "BATCH_SIZE=64\n",
    "NUM_CLASSES=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affenpinscher\r\n",
      "afghan_hound\r\n",
      "african_hunting_dog\r\n",
      "airedale\r\n",
      "american_staffordshire_terrier\r\n",
      "appenzeller\r\n",
      "australian_terrier\r\n",
      "basenji\r\n",
      "basset\r\n",
      "beagle\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/train/ | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.preprocessing.image.ImageDataGenerator"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_keras.preprocessing.image.ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf_keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input\n",
    "                                     ,rotation_range=45\n",
    "                                     ,width_shift_range=0.2\n",
    "                                     ,height_shift_range=0.2\n",
    "                                     ,shear_range=0.2\n",
    "                                     ,zoom_range=0.25\n",
    "                                     ,horizontal_flip=True\n",
    "                                     ,fill_mode='nearest'\n",
    "                                  )\n",
    "\n",
    "train_batches = train_generator.flow_from_directory(\n",
    "    train_folder, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE,shuffle=True, seed=13,class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "valid_generator =  tf_keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "\n",
    "valid_batches = valid_generator.flow_from_directory(\n",
    "    valid_folder, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = train_batches.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.mobilenet import MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.layers[-6].output\n",
    "#predictions = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.layers[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(model,show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=train_batches.n//BATCH_SIZE, \n",
    "                    validation_data=valid_batches\n",
    "                    ,  validation_steps=valid_batches.n // BATCH_SIZE, verbose=2,workers=4\n",
    "                    , epochs=3\n",
    "                   \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dog_breed_tf.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'w') as file_handler:\n",
    "    for item in train_batches.class_indices.keys():\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model\n",
    "!tensorflowjs_converter --input_format keras dog_breed_tf.h5 model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects={'relu6': tf_keras.applications.mobilenet.relu6,'DepthwiseConv2D': tf_keras.applications.mobilenet.DepthwiseConv2D}\n",
    "\n",
    "model = tf.keras.models.load_model(model_name,custom_objects=custom_objects )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir =\"tf_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tf_models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f95fdc69860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "custom_objects={'relu6': tf_keras.applications.mobilenet.relu6,'DepthwiseConv2D': tf_keras.applications.mobilenet.DepthwiseConv2D}\n",
    "dogbreed_estimator = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "                                                    model_dir=model_dir,custom_objects=custom_objects )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "?dogbreed_estimator.export_savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_for_production(model, version, path='prod_models'):\n",
    "    K.set_learning_phase(0)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    export_path = os.path.join(\n",
    "        tf.compat.as_bytes(path),tf.compat.as_bytes(version))\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    model_input = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "    model_output = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "\n",
    "    prediction_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs={'inputs': model_input},\n",
    "            outputs={'output': model_output},\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    with K.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(\n",
    "            sess=sess, tags=[tf.saved_model.tag_constants.SERVING],\n",
    "            signature_def_map={\n",
    "                'predict':\n",
    "                    prediction_signature,\n",
    "            })\n",
    "\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "?shutil.rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_saved_model_old(model,path=\"prod_models\"):\n",
    "    shutil.rmtree(path,ignore_errors=True)\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        signature = tf.saved_model.signature_def_utils.predict_signature_def(                                                                        \n",
    "        inputs={'image': model.input}, outputs={'scores': model.output})                                                                         \n",
    "\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(path)                                                                    \n",
    "        builder.add_meta_graph_and_variables(                                                                                                        \n",
    "        sess=K.get_session(),                                                                                                                    \n",
    "        tags=[tf.saved_model.tag_constants.SERVING],                                                                                             \n",
    "        signature_def_map={                                                                                                                      \n",
    "            tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:                                                                \n",
    "                signature                                                                                                                        \n",
    "        })                                                                                                                                       \n",
    "        builder.save()\n",
    "        \n",
    "def export_saved_model(model,path=\"prod_models\"):\n",
    "    shutil.rmtree(path,ignore_errors=True)\n",
    "\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(path)\n",
    "    signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "      inputs={\"input\": model.input},\n",
    "      outputs={\"output\": model.output})\n",
    " \n",
    "    with K.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(sess=sess,\n",
    "        tags=[tf.saved_model.tag_constants.SERVING],\n",
    "        signature_def_map={\"predict\": signature, \"serving_default\": signature} )\n",
    "    \n",
    "        builder.save()\n",
    "        \n",
    "def export_saved_model3(model,path=\"prod_models\"):\n",
    "    shutil.rmtree(path,ignore_errors=True)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    #with K.get_session() as sess:\n",
    "\n",
    "        signature = tf.saved_model.signature_def_utils.predict_signature_def(                                                                        \n",
    "        inputs={'image': model.input}, outputs={'scores': model.output})                                                                         \n",
    "\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(path)                                                                    \n",
    "        builder.add_meta_graph_and_variables(                                                                                                        \n",
    "            sess = sess,\n",
    "            #sess=K.get_session(),                                                                                                                    \n",
    "            tags=[tf.saved_model.tag_constants.SERVING],                                                                                             \n",
    "            signature_def_map={                                                                                                                      \n",
    "                tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:                                                                \n",
    "                    signature                                                                                                                        \n",
    "            })                                                                                                                                       \n",
    "        builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model_for_production(model=model,version=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[Node: conv1/kernel/Read/ReadVariableOp = ReadVariableOp[_class=[\"loc:@conv1/kernel\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/kernel)]]\n\nCaused by op 'conv1/kernel/Read/ReadVariableOp', defined at:\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-2eb70942eac3>\", line 3, in <module>\n    model = tf.keras.models.load_model(model_name,custom_objects=custom_objects )\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 229, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 306, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1162, in from_config\n    process_node(layer, node_data)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1120, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 696, in __call__\n    self.build(input_shapes)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 160, in build\n    dtype=self.dtype)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 460, in add_variable\n    return self.add_weight(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 534, in add_weight\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 497, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in make_variable\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2196, in default_variable_creator\n    constraint=constraint)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 312, in __init__\n    constraint=constraint)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 483, in _init_from_args\n    value = self._read_variable_op()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 742, in _read_variable_op\n    self._dtype)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 507, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[Node: conv1/kernel/Read/ReadVariableOp = ReadVariableOp[_class=[\"loc:@conv1/kernel\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[Node: conv1/kernel/Read/ReadVariableOp = ReadVariableOp[_class=[\"loc:@conv1/kernel\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-08fdc65ceeb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexport_saved_model3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-1b692972f92b>\u001b[0m in \u001b[0;36mexport_saved_model3\u001b[0;34m(model, path)\u001b[0m\n\u001b[1;32m     47\u001b[0m             signature_def_map={                                                                                                                      \n\u001b[1;32m     48\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                     \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             })                                                                                                                                       \n\u001b[1;32m     51\u001b[0m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36madd_meta_graph_and_variables\u001b[0;34m(self, sess, tags, signature_def_map, assets_collection, legacy_init_op, clear_devices, main_op, strip_default_attrs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;31m# SavedModel can be copied or moved, this avoids the checkpoint state to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;31m# become outdated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# Export the meta graph def.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1668\u001b[0m                   save_path))\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1651\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[Node: conv1/kernel/Read/ReadVariableOp = ReadVariableOp[_class=[\"loc:@conv1/kernel\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/kernel)]]\n\nCaused by op 'conv1/kernel/Read/ReadVariableOp', defined at:\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-2eb70942eac3>\", line 3, in <module>\n    model = tf.keras.models.load_model(model_name,custom_objects=custom_objects )\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 229, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 306, in model_from_config\n    return deserialize(config, custom_objects=custom_objects)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py\", line 64, in deserialize\n    printable_module_name='layer')\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\", line 173, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1162, in from_config\n    process_node(layer, node_data)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1120, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 696, in __call__\n    self.build(input_shapes)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 160, in build\n    dtype=self.dtype)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 460, in add_variable\n    return self.add_weight(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 534, in add_weight\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 497, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1873, in make_variable\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2234, in variable\n    use_resource=use_resource)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2224, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2196, in default_variable_creator\n    constraint=constraint)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 312, in __init__\n    constraint=constraint)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 483, in _init_from_args\n    value = self._read_variable_op()\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 742, in _read_variable_op\n    self._dtype)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 507, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable conv1/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/conv1/kernel)\n\t [[Node: conv1/kernel/Read/ReadVariableOp = ReadVariableOp[_class=[\"loc:@conv1/kernel\"], dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "export_saved_model3(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_saved_model(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toco "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_frozen_graph() missing 2 required positional arguments: 'input_arrays' and 'output_arrays'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dab9f12aa312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTocoConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_frozen_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prod_models/1/saved_model.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: from_frozen_graph() missing 2 required positional arguments: 'input_arrays' and 'output_arrays'"
     ]
    }
   ],
   "source": [
    "tf.contrib.lite.TocoConverter.from_frozen_graph('prod_models/1/saved_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'TocoConverter' has no attribute 'from_keras_model_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-711de8669b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTocoConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converted_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TocoConverter' has no attribute 'from_keras_model_file'"
     ]
    }
   ],
   "source": [
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file(model_name)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?dogbreed_estimator.export_savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogbreed_estimator.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogbreed_estimator = tf.keras.estimator.model_to_estimator(keras_model=model,\n",
    "                                                    model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp /home/ubuntu/custom/deeplizrd/dog_breed.h5 gs://np-training-public/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls /home/ubuntu/.kaggle/competitions/dog-breed-identification/train_folder/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
