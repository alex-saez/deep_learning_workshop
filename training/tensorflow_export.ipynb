{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:29:47.032972Z",
     "start_time": "2018-07-11T03:29:46.096801Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow==1.9.0rc2 coremltools==0.8 tensorflowjs==0.5.0\n",
    "# pip install tf-nightly==1.10.0.dev20180707\n",
    "# nano /usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:30.369753Z",
     "start_time": "2018-07-08T20:54:30.367528Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install coremltools==0.8 Keras==2.1.6 imutils==0.4.6 opencv-python==3.4.1.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:39:20.128588Z",
     "start_time": "2018-07-08T20:39:20.123862Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://github.com/ianlokh/MobileNet-On-CoreML.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.735276Z",
     "start_time": "2018-07-11T11:34:17.854186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING:root:Keras version 2.1.4 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n",
      "WARNING:root:TensorFlow version 1.10.0-dev20180707 detected. Last version known to be fully compatible is 1.5.0 .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import coremltools\n",
    "import tensorflowjs as tfjs\n",
    "from tensorflow.python import keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:11:42.272715Z",
     "start_time": "2018-07-11T03:11:42.270002Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#from keras import backend as K\n",
    "#from keras.models import load_model\n",
    "#from keras.utils.generic_utils import CustomObjectScope\n",
    "#from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "#from keras.preprocessing import image\n",
    "#from keras.applications.mobilenet import preprocess_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:07:49.349981Z",
     "start_time": "2018-07-08T16:07:47.491723Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:05:49.538921Z",
     "start_time": "2018-07-08T21:05:49.402650Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:11:42.400955Z",
     "start_time": "2018-07-11T03:11:42.274883Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.740006Z",
     "start_time": "2018-07-11T11:34:26.737074Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('labels.txt') as f:\n",
    "    labels = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.744998Z",
     "start_time": "2018-07-11T11:34:26.741899Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_dict = {idx:label for (idx,label) in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.757477Z",
     "start_time": "2018-07-11T11:34:26.747071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'scottish_deerhound',\n",
       " 1: 'maltese_dog',\n",
       " 2: 'afghan_hound',\n",
       " 3: 'entlebucher',\n",
       " 4: 'bernese_mountain_dog',\n",
       " 5: 'shih-tzu',\n",
       " 6: 'great_pyrenees',\n",
       " 7: 'pomeranian',\n",
       " 8: 'basenji',\n",
       " 9: 'samoyed',\n",
       " 10: 'airedale',\n",
       " 11: 'tibetan_terrier',\n",
       " 12: 'leonberg',\n",
       " 13: 'cairn',\n",
       " 14: 'beagle',\n",
       " 15: 'japanese_spaniel',\n",
       " 16: 'australian_terrier',\n",
       " 17: 'blenheim_spaniel',\n",
       " 18: 'miniature_pinscher',\n",
       " 19: 'irish_wolfhound',\n",
       " 20: 'lakeland_terrier',\n",
       " 21: 'saluki',\n",
       " 22: 'papillon',\n",
       " 23: 'whippet',\n",
       " 24: 'siberian_husky',\n",
       " 25: 'norwegian_elkhound',\n",
       " 26: 'pug',\n",
       " 27: 'chow',\n",
       " 28: 'italian_greyhound',\n",
       " 29: 'pembroke',\n",
       " 30: 'ibizan_hound',\n",
       " 31: 'border_terrier',\n",
       " 32: 'newfoundland',\n",
       " 33: 'lhasa',\n",
       " 34: 'silky_terrier',\n",
       " 35: 'bedlington_terrier',\n",
       " 36: 'dandie_dinmont',\n",
       " 37: 'irish_setter',\n",
       " 38: 'sealyham_terrier',\n",
       " 39: 'rhodesian_ridgeback',\n",
       " 40: 'old_english_sheepdog',\n",
       " 41: 'collie',\n",
       " 42: 'boston_bull',\n",
       " 43: 'english_foxhound',\n",
       " 44: 'bouvier_des_flandres',\n",
       " 45: 'african_hunting_dog',\n",
       " 46: 'schipperke',\n",
       " 47: 'kelpie',\n",
       " 48: 'weimaraner',\n",
       " 49: 'bloodhound',\n",
       " 50: 'bluetick',\n",
       " 51: 'saint_bernard',\n",
       " 52: 'labrador_retriever',\n",
       " 53: 'chesapeake_bay_retriever',\n",
       " 54: 'norfolk_terrier',\n",
       " 55: 'english_setter',\n",
       " 56: 'wire-haired_fox_terrier',\n",
       " 57: 'kerry_blue_terrier',\n",
       " 58: 'scotch_terrier',\n",
       " 59: 'yorkshire_terrier',\n",
       " 60: 'groenendael',\n",
       " 61: 'greater_swiss_mountain_dog',\n",
       " 62: 'irish_terrier',\n",
       " 63: 'basset',\n",
       " 64: 'keeshond',\n",
       " 65: 'west_highland_white_terrier',\n",
       " 66: 'gordon_setter',\n",
       " 67: 'malamute',\n",
       " 68: 'affenpinscher',\n",
       " 69: 'toy_poodle',\n",
       " 70: 'clumber',\n",
       " 71: 'mexican_hairless',\n",
       " 72: 'dingo',\n",
       " 73: 'standard_poodle',\n",
       " 74: 'miniature_poodle',\n",
       " 75: 'staffordshire_bullterrier',\n",
       " 76: 'welsh_springer_spaniel',\n",
       " 77: 'toy_terrier',\n",
       " 78: 'sussex_spaniel',\n",
       " 79: 'norwich_terrier',\n",
       " 80: 'appenzeller',\n",
       " 81: 'irish_water_spaniel',\n",
       " 82: 'miniature_schnauzer',\n",
       " 83: 'black-and-tan_coonhound',\n",
       " 84: 'cardigan',\n",
       " 85: 'dhole',\n",
       " 86: 'shetland_sheepdog',\n",
       " 87: 'rottweiler',\n",
       " 88: 'english_springer',\n",
       " 89: 'great_dane',\n",
       " 90: 'german_short-haired_pointer',\n",
       " 91: 'boxer',\n",
       " 92: 'bull_mastiff',\n",
       " 93: 'borzoi',\n",
       " 94: 'pekinese',\n",
       " 95: 'cocker_spaniel',\n",
       " 96: 'american_staffordshire_terrier',\n",
       " 97: 'doberman',\n",
       " 98: 'brittany_spaniel',\n",
       " 99: 'malinois',\n",
       " 100: 'standard_schnauzer',\n",
       " 101: 'flat-coated_retriever',\n",
       " 102: 'redbone',\n",
       " 103: 'border_collie',\n",
       " 104: 'curly-coated_retriever',\n",
       " 105: 'kuvasz',\n",
       " 106: 'chihuahua',\n",
       " 107: 'soft-coated_wheaten_terrier',\n",
       " 108: 'french_bulldog',\n",
       " 109: 'vizsla',\n",
       " 110: 'tibetan_mastiff',\n",
       " 111: 'german_shepherd',\n",
       " 112: 'giant_schnauzer',\n",
       " 113: 'walker_hound',\n",
       " 114: 'otterhound',\n",
       " 115: 'golden_retriever',\n",
       " 116: 'brabancon_griffon',\n",
       " 117: 'komondor',\n",
       " 118: 'briard',\n",
       " 119: 'eskimo_dog'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.762880Z",
     "start_time": "2018-07-11T11:34:26.759185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": \"scottish_deerhound\", \"1\": \"maltese_dog\", \"2\": \"afghan_hound\", \"3\": \"entlebucher\", \"4\": \"bernese_mountain_dog\", \"5\": \"shih-tzu\", \"6\": \"great_pyrenees\", \"7\": \"pomeranian\", \"8\": \"basenji\", \"9\": \"samoyed\", \"10\": \"airedale\", \"11\": \"tibetan_terrier\", \"12\": \"leonberg\", \"13\": \"cairn\", \"14\": \"beagle\", \"15\": \"japanese_spaniel\", \"16\": \"australian_terrier\", \"17\": \"blenheim_spaniel\", \"18\": \"miniature_pinscher\", \"19\": \"irish_wolfhound\", \"20\": \"lakeland_terrier\", \"21\": \"saluki\", \"22\": \"papillon\", \"23\": \"whippet\", \"24\": \"siberian_husky\", \"25\": \"norwegian_elkhound\", \"26\": \"pug\", \"27\": \"chow\", \"28\": \"italian_greyhound\", \"29\": \"pembroke\", \"30\": \"ibizan_hound\", \"31\": \"border_terrier\", \"32\": \"newfoundland\", \"33\": \"lhasa\", \"34\": \"silky_terrier\", \"35\": \"bedlington_terrier\", \"36\": \"dandie_dinmont\", \"37\": \"irish_setter\", \"38\": \"sealyham_terrier\", \"39\": \"rhodesian_ridgeback\", \"40\": \"old_english_sheepdog\", \"41\": \"collie\", \"42\": \"boston_bull\", \"43\": \"english_foxhound\", \"44\": \"bouvier_des_flandres\", \"45\": \"african_hunting_dog\", \"46\": \"schipperke\", \"47\": \"kelpie\", \"48\": \"weimaraner\", \"49\": \"bloodhound\", \"50\": \"bluetick\", \"51\": \"saint_bernard\", \"52\": \"labrador_retriever\", \"53\": \"chesapeake_bay_retriever\", \"54\": \"norfolk_terrier\", \"55\": \"english_setter\", \"56\": \"wire-haired_fox_terrier\", \"57\": \"kerry_blue_terrier\", \"58\": \"scotch_terrier\", \"59\": \"yorkshire_terrier\", \"60\": \"groenendael\", \"61\": \"greater_swiss_mountain_dog\", \"62\": \"irish_terrier\", \"63\": \"basset\", \"64\": \"keeshond\", \"65\": \"west_highland_white_terrier\", \"66\": \"gordon_setter\", \"67\": \"malamute\", \"68\": \"affenpinscher\", \"69\": \"toy_poodle\", \"70\": \"clumber\", \"71\": \"mexican_hairless\", \"72\": \"dingo\", \"73\": \"standard_poodle\", \"74\": \"miniature_poodle\", \"75\": \"staffordshire_bullterrier\", \"76\": \"welsh_springer_spaniel\", \"77\": \"toy_terrier\", \"78\": \"sussex_spaniel\", \"79\": \"norwich_terrier\", \"80\": \"appenzeller\", \"81\": \"irish_water_spaniel\", \"82\": \"miniature_schnauzer\", \"83\": \"black-and-tan_coonhound\", \"84\": \"cardigan\", \"85\": \"dhole\", \"86\": \"shetland_sheepdog\", \"87\": \"rottweiler\", \"88\": \"english_springer\", \"89\": \"great_dane\", \"90\": \"german_short-haired_pointer\", \"91\": \"boxer\", \"92\": \"bull_mastiff\", \"93\": \"borzoi\", \"94\": \"pekinese\", \"95\": \"cocker_spaniel\", \"96\": \"american_staffordshire_terrier\", \"97\": \"doberman\", \"98\": \"brittany_spaniel\", \"99\": \"malinois\", \"100\": \"standard_schnauzer\", \"101\": \"flat-coated_retriever\", \"102\": \"redbone\", \"103\": \"border_collie\", \"104\": \"curly-coated_retriever\", \"105\": \"kuvasz\", \"106\": \"chihuahua\", \"107\": \"soft-coated_wheaten_terrier\", \"108\": \"french_bulldog\", \"109\": \"vizsla\", \"110\": \"tibetan_mastiff\", \"111\": \"german_shepherd\", \"112\": \"giant_schnauzer\", \"113\": \"walker_hound\", \"114\": \"otterhound\", \"115\": \"golden_retriever\", \"116\": \"brabancon_griffon\", \"117\": \"komondor\", \"118\": \"briard\", \"119\": \"eskimo_dog\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.768252Z",
     "start_time": "2018-07-11T11:34:26.764916Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('label_classes.json', 'w') as fp:\n",
    "    json.dump(labels_dict, fp, indent=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:41.474461Z",
     "start_time": "2018-07-11T03:31:41.470278Z"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:26.774709Z",
     "start_time": "2018-07-11T11:34:26.769967Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_image(url,ext=\".jpg\"):\n",
    "    url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()\n",
    "    file_path = f'{DOWNLOAD_FOLDER}/{url_hash}.{ext}'\n",
    "    \n",
    "    urllib.request.urlretrieve(url,file_path)\n",
    "\n",
    "    img = tf_keras.preprocessing.image.load_img(file_path, target_size=(224, 224))\n",
    "    return img\n",
    "\n",
    "def predict(im, model, labels,n=5):\n",
    "    out = model.predict(img_arr[None,:,:,:]).flatten()\n",
    "    top_indices = out.argsort()[::-1][:n]\n",
    "    \n",
    "    top_probability = out[top_indices]\n",
    "    top_labels = np.array(labels)[top_indices]\n",
    "    \n",
    "    res = list(zip(top_labels,top_probability))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_top_n_predictions(preds,labels,n=5):\n",
    "    if len(preds.shape) >1:\n",
    "        preds = preds.flatten()\n",
    "    top_idxs = (-preds).argsort()[:n]\n",
    "    res =[]\n",
    "    for idx in top_idxs:\n",
    "        res.append((labels[idx],preds[idx] ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T03:38:04.107976Z",
     "start_time": "2018-07-08T03:38:04.062131Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:27.117140Z",
     "start_time": "2018-07-11T11:34:27.115017Z"
    }
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_FOLDER='downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:28.787362Z",
     "start_time": "2018-07-11T11:34:28.781416Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(DOWNLOAD_FOLDER,ignore_errors=True)\n",
    "os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:08:23.293353Z",
     "start_time": "2018-07-08T16:08:23.289765Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:45.304088Z",
     "start_time": "2018-07-11T03:31:45.079946Z"
    }
   },
   "outputs": [],
   "source": [
    "img_url = \"https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12231410/Labrador-Retriever-On-White-01.jpg\"\n",
    "img = download_image(img_url)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:45.404201Z",
     "start_time": "2018-07-11T03:31:45.400811Z"
    }
   },
   "outputs": [],
   "source": [
    "img_preprocessed = keras.applications.mobilenet.preprocess_input (\n",
    "        tf_keras.preprocessing.image.img_to_array(img)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:45.641024Z",
     "start_time": "2018-07-11T03:31:45.637869Z"
    }
   },
   "outputs": [],
   "source": [
    "img_arr = keras.applications.mobilenet.preprocess_input (\n",
    "        tf_keras.preprocessing.image.img_to_array(img)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:46.105813Z",
     "start_time": "2018-07-11T03:31:46.102349Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_keras_model(model_path):\n",
    "    with keras.utils.generic_utils.CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "        keras_model =  keras.models.load_model(model_path)\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:50.836509Z",
     "start_time": "2018-07-11T03:31:46.374561Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model = load_keras_model(model_path='dog_breed.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:51.336378Z",
     "start_time": "2018-07-11T03:31:50.838607Z"
    }
   },
   "outputs": [],
   "source": [
    "predict(im=img_preprocessed ,model=keras_model, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:34:36.727580Z",
     "start_time": "2018-07-11T11:34:36.724906Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python import keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:49:00.182526Z",
     "start_time": "2018-07-08T21:49:00.180493Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.python.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.applications.mobilenet.relu6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:26:41.661732Z",
     "start_time": "2018-07-11T03:26:41.658224Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_keras_using_tf(model_path):\n",
    "\n",
    "    custom_objects={'relu6': tf_keras.applications.mobilenet.relu6,'DepthwiseConv2D': tf_keras.applications.mobilenet.DepthwiseConv2D}\n",
    "    \n",
    "    model = tf_keras.models.load_model(model_path,custom_objects=custom_objects)\n",
    "        \n",
    "    mobilenet_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, custom_objects={'relu6': tf_keras.applications.mobilenet.relu6})\n",
    "    \n",
    "    return mobilenet_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:26:54.130735Z",
     "start_time": "2018-07-11T03:26:46.627026Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_keras_model = load_keras_using_tf('dog_breed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:26:54.138689Z",
     "start_time": "2018-07-11T03:26:54.133887Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"input_1\": img_preprocessed[None,:,:,:]},\n",
    "  num_epochs=1,\n",
    "  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:26:54.306238Z",
     "start_time": "2018-07-11T03:26:54.140896Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = list(tf_keras_model.predict(input_fn=predict_input_fn))\n",
    "preds= predictions[0]['dense_1']\n",
    "get_top_n_predictions(preds=preds,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:12:44.909781Z",
     "start_time": "2018-07-11T03:12:43.287885Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:43:40.679255Z",
     "start_time": "2018-07-08T21:43:40.665524Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:51:08.967387Z",
     "start_time": "2018-07-08T21:51:08.955512Z"
    }
   },
   "outputs": [],
   "source": [
    "?tfjs.converters.save_keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:31:59.337795Z",
     "start_time": "2018-07-11T03:31:56.791689Z"
    }
   },
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(\n",
    "    model = keras_model, \n",
    "    artifacts_dir='tfjs_artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:32:51.706137Z",
     "start_time": "2018-07-11T03:32:51.676758Z"
    }
   },
   "outputs": [],
   "source": [
    "?tf.contrib.lite.TocoConverter.from_keras_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:35:06.927061Z",
     "start_time": "2018-07-11T11:34:59.099793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TOCO failed see console for info.\nb'2018-07-11 07:35:06.749379: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:35:06.762622: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:35:06.788503: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:35:06.791154: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:35:06.793722: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 8028160 bytes, theoretical optimal value: 6538240 bytes.\\n2018-07-11 07:35:06.794062: I tensorflow/contrib/lite/toco/toco_tooling.cc:324] Estimated count of arithmetic ops: 1.14073 billion (note that a multiply-add is counted as 2 ops).\\n2018-07-11 07:35:06.794463: F tensorflow/contrib/lite/toco/tflite/export.cc:315] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.\\n'\nNone\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7fdc9e749e8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTocoConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog_breed.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog_breed.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mquantize_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mdump_graphviz_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_graphviz_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         dump_graphviz_video=self.dump_graphviz_video)\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    245\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    247\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       raise RuntimeError(\"TOCO failed see console for info.\\n%s\\n%s\\n\" %\n\u001b[0;32m--> 106\u001b[0;31m                          (stdout, stderr))\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TOCO failed see console for info.\nb'2018-07-11 07:35:06.749379: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:35:06.762622: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:35:06.788503: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:35:06.791154: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:35:06.793722: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 8028160 bytes, theoretical optimal value: 6538240 bytes.\\n2018-07-11 07:35:06.794062: I tensorflow/contrib/lite/toco/toco_tooling.cc:324] Estimated count of arithmetic ops: 1.14073 billion (note that a multiply-add is counted as 2 ops).\\n2018-07-11 07:35:06.794463: F tensorflow/contrib/lite/toco/tflite/export.cc:315] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.\\n'\nNone\n"
     ]
    }
   ],
   "source": [
    "with tf_keras.utils.generic_utils.CustomObjectScope({'relu6': tf_keras.applications.mobilenet.relu6,'DepthwiseConv2D': tf_keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"dog_breed.h5\")\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    open(\"dog_breed.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:36:26.119074Z",
     "start_time": "2018-07-11T11:36:18.609369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 137 variables to const ops.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TOCO failed see console for info.\nb'2018-07-11 07:36:26.041045: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:36:26.053084: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:36:26.078778: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:36:26.081666: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:36:26.084547: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 8028160 bytes, theoretical optimal value: 6538240 bytes.\\n2018-07-11 07:36:26.084911: I tensorflow/contrib/lite/toco/toco_tooling.cc:324] Estimated count of arithmetic ops: 1.14073 billion (note that a multiply-add is counted as 2 ops).\\n2018-07-11 07:36:26.085341: F tensorflow/contrib/lite/toco/tflite/export.cc:315] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.\\n'\nNone\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-89edf17d7fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTocoConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog_breed_tf.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog_breed.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mquantize_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mdump_graphviz_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_graphviz_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         dump_graphviz_video=self.dump_graphviz_video)\n\u001b[0m\u001b[1;32m    376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    245\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    247\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       raise RuntimeError(\"TOCO failed see console for info.\\n%s\\n%s\\n\" %\n\u001b[0;32m--> 106\u001b[0;31m                          (stdout, stderr))\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TOCO failed see console for info.\nb'2018-07-11 07:36:26.041045: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:36:26.053084: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 398 operators, 632 arrays (0 quantized)\\n2018-07-11 07:36:26.078778: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:36:26.081666: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 98 operators, 224 arrays (0 quantized)\\n2018-07-11 07:36:26.084547: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 8028160 bytes, theoretical optimal value: 6538240 bytes.\\n2018-07-11 07:36:26.084911: I tensorflow/contrib/lite/toco/toco_tooling.cc:324] Estimated count of arithmetic ops: 1.14073 billion (note that a multiply-add is counted as 2 ops).\\n2018-07-11 07:36:26.085341: F tensorflow/contrib/lite/toco/tflite/export.cc:315] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: TensorFlowMinimum.\\n'\nNone\n"
     ]
    }
   ],
   "source": [
    "with tf_keras.utils.generic_utils.CustomObjectScope({'relu6': tf_keras.applications.mobilenet.relu6,'DepthwiseConv2D': tf_keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"dog_breed_tf.h5\")\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    open(\"dog_breed.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T11:33:57.733320Z",
     "start_time": "2018-07-11T11:33:57.719818Z"
    }
   },
   "outputs": [],
   "source": [
    "with keras.utils.generic_utils.CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"dog_breed.h5\")\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"dog_breed.tflite\", \"wb\").write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coreml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.apple.com/documentation/vision/classifying_images_with_vision_and_core_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:36:24.510994Z",
     "start_time": "2018-07-11T03:36:22.637953Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = 1./255\n",
    "coreml_model = coremltools.converters.keras.convert(keras_model,\n",
    "                                                    input_names = 'image',\n",
    "                                                    output_names = 'output',\n",
    "                                                    image_input_names = 'image',\n",
    "                                                    image_scale = scale,\n",
    "                                                    red_bias = -123.68 * scale,\n",
    "                                                    green_bias = -116.779 * scale,\n",
    "                                                    blue_bias = -103.939 * scale,\n",
    "                                                    class_labels=labels)\n",
    "\n",
    "coreml_model.author = 'Ian Lo'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Model to classify 17 different Singaporean dishes'\n",
    "coreml_model.input_description['image'] = 'Images from camera in CVPixelBuffer'\n",
    "coreml_model.output_description['output'] = 'Predicted dishes'\n",
    "\n",
    "coreml_model.save('dog_breed.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:09:32.234284Z",
     "start_time": "2018-07-08T16:09:32.230595Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:08:57.747762Z",
     "start_time": "2018-07-08T16:08:57.744833Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:09:05.333196Z",
     "start_time": "2018-07-08T16:08:59.462165Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.utils import CustomObjectScope\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "with CustomObjectScope({'relu6': relu6}):\n",
    "    keras_mobilenet= tf.keras.models.load_model(filepath='dog_breed.h5')\n",
    "\n",
    "    mobilenet_estimator = tf.keras.estimator.model_to_estimator(keras_model=keras_mobilenet,  custom_objects={'relu6': relu6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T13:58:21.796858Z",
     "start_time": "2018-07-08T13:58:21.768322Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T14:57:51.895130Z",
     "start_time": "2018-07-08T14:57:51.878686Z"
    }
   },
   "outputs": [],
   "source": [
    "??preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:09:28.674874Z",
     "start_time": "2018-07-08T16:09:28.671074Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"input_1\": preprocess_input(image.img_to_array(img))[None,:,:,:]},\n",
    "  num_epochs=1,\n",
    "  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:09:31.409066Z",
     "start_time": "2018-07-08T16:09:29.694503Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = list(mobilenet_estimator.predict(input_fn=predict_input_fn))\n",
    "#predicted_classes = [p[\"classes\"] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:09:33.554701Z",
     "start_time": "2018-07-08T16:09:33.550492Z"
    }
   },
   "outputs": [],
   "source": [
    "preds= predictions[0]['dense_1']\n",
    "get_top_n_predictions(preds=preds,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(mobilenet_estimator.predict(input_fn=predict_input_fn))\n",
    "preds= predictions[0]['dense_1']\n",
    "get_top_n_predictions(preds=preds,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:47:27.256922Z",
     "start_time": "2018-07-08T16:47:27.254058Z"
    }
   },
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    inputs = {\n",
    "        'input_1': tf.placeholder(tf.float32, [None, 224, 224, 3]),\n",
    "      }\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:47:28.053527Z",
     "start_time": "2018-07-08T16:47:28.025337Z"
    }
   },
   "outputs": [],
   "source": [
    "mobilenet_estimator.export_savedmodel('tmp',serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:46:28.654976Z",
     "start_time": "2018-07-08T16:46:28.650091Z"
    }
   },
   "outputs": [],
   "source": [
    "?tf.estimator.export.ServingInputReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:46:09.873671Z",
     "start_time": "2018-07-08T16:46:09.868949Z"
    }
   },
   "outputs": [],
   "source": [
    "?mobilenet_estimator.export_savedmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T14:00:02.245988Z",
     "start_time": "2018-07-08T14:00:02.115615Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls tmp/1531058391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T15:43:51.673308Z",
     "start_time": "2018-07-08T15:43:51.666090Z"
    }
   },
   "outputs": [],
   "source": [
    "?tf.estimator.export.ServingInputReceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T15:49:19.964243Z",
     "start_time": "2018-07-08T15:49:19.936449Z"
    }
   },
   "outputs": [],
   "source": [
    "from te.contrib.lite import TocoConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:39:06.027564Z",
     "start_time": "2018-07-08T19:39:05.904437Z"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:39:01.987886Z",
     "start_time": "2018-07-08T19:39:01.862719Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls dog_breed.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:47:11.467191Z",
     "start_time": "2018-07-08T19:47:11.462083Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.contrib.lite.TocoConverter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:09:51.178029Z",
     "start_time": "2018-07-08T20:09:51.175193Z"
    }
   },
   "outputs": [],
   "source": [
    "?converter.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:52.070080Z",
     "start_time": "2018-07-08T20:55:50.196529Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:52.618672Z",
     "start_time": "2018-07-08T20:55:52.506970Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:56:16.214261Z",
     "start_time": "2018-07-08T20:55:57.840818Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.python.keras.applications import mobilenet\n",
    "from tensorflow.python.keras.models import load_model\n",
    "with CustomObjectScope({'relu6': mobilenet.relu6,'DepthwiseConv2D': mobilenet.DepthwiseConv2D}):\n",
    "    model = load_model('dog_breed.h5')\n",
    "    converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"dog_breed.h5\")\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    open(\"dog_breed.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:59:04.817204Z",
     "start_time": "2018-07-08T20:58:59.868870Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    model = keras.models.load_model('dog_breed.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Keras model was trained on ImageNet, need to subtract the mean from RGB\n",
    "\n",
    "- red_bias=-123.68\n",
    "- green_bias=-116.78\n",
    "- blue_bias=-103.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:01:52.469669Z",
     "start_time": "2018-07-08T21:01:50.646514Z"
    }
   },
   "outputs": [],
   "source": [
    "scale = 1./255\n",
    "coreml_model = coremltools.converters.keras.convert(model,\n",
    "                                                    input_names = 'image',\n",
    "                                                    output_names = 'output',\n",
    "                                                    image_input_names = 'image',\n",
    "                                                    image_scale = scale,\n",
    "                                                    red_bias = -123.68 * scale,\n",
    "                                                    green_bias = -116.779 * scale,\n",
    "                                                    blue_bias = -103.939 * scale,\n",
    "                                                    class_labels=labels)\n",
    "\n",
    "coreml_model.author = 'Ian Lo'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Model to classify 17 different Singaporean dishes'\n",
    "coreml_model.input_description['image'] = 'Images from camera in CVPixelBuffer'\n",
    "coreml_model.output_description['output'] = 'Predicted dishes'\n",
    "\n",
    "coreml_model.save('dog_breed.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T21:01:29.104272Z",
     "start_time": "2018-07-08T21:01:28.968221Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:22:49.135433Z",
     "start_time": "2018-07-08T20:22:49.104897Z"
    }
   },
   "outputs": [],
   "source": [
    "? converter.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomObjectScope({'relu6': keras.applications.mobilenet.relu6,'DepthwiseConv2D': keras.applications.mobilenet.DepthwiseConv2D}):\n",
    "    model =  load_model('dog_breed.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T03:33:38.306082Z",
     "start_time": "2018-07-11T03:33:38.271599Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"dog_breed.h5\")\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:36:03.404531Z",
     "start_time": "2018-07-08T19:36:03.396372Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:10:48.353090Z",
     "start_time": "2018-07-08T16:10:48.338690Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file('dog_breed.h5')\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:11:18.694336Z",
     "start_time": "2018-07-08T16:11:18.690611Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T16:10:07.682433Z",
     "start_time": "2018-07-08T16:10:04.595375Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file('dog_breed.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
