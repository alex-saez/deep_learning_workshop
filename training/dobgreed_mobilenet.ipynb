{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/59/41/ba6ac9b63c5bfb90377784e29c4f4c478c74f53e020fa56237c939674f2d/tensorflow_gpu-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (216.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 216.3MB 3.0kB/s eta 0:00:01   33% |██████████▉                     | 73.3MB 61.2MB/s eta 0:00:03    81% |██████████████████████████▏     | 177.2MB 33.9MB/s eta 0:00:02    90% |█████████████████████████████   | 196.0MB 47.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Keras==2.1.6\n",
      "  Downloading https://files.pythonhosted.org/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339kB)\n",
      "\u001b[K    100% |████████████████████████████████| 348kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from tensorflow-gpu==1.8.0)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/8d/6664518f9b6ced0aa41cf50b989740909261d4c212557400c48e5cda0804/absl-py-0.2.2.tar.gz (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.9.0,>=1.8.0 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 185kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from tensorflow-gpu==1.8.0)\n",
      "Collecting protobuf>=3.4.0 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/f0/db040681187496d10ac50ad167a8fd5f953d115b16a7085e19193a6abfd2/protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 100kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/13/b05bbd05d9f0c19e5746f149a285aa81f7c353e231ffecdb237c6e2ad3cc/grpcio-1.13.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.1MB 78kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from tensorflow-gpu==1.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from tensorflow-gpu==1.8.0)\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting h5py (from Keras==2.1.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 253kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from Keras==2.1.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from Keras==2.1.6)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 818kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow-gpu==1.8.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow-gpu==1.8.0)\n",
      "Building wheels for collected packages: absl-py, gast, html5lib\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/a0/f8/e9/1933dbb3447ea6ef57062fd5461cb118deb8c2ed074e8344bf\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built absl-py gast html5lib\n",
      "Installing collected packages: absl-py, markdown, html5lib, bleach, protobuf, werkzeug, tensorboard, grpcio, astor, gast, tensorflow-gpu, h5py, Keras\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.1.3\n",
      "    Uninstalling bleach-2.1.3:\n",
      "      Successfully uninstalled bleach-2.1.3\n",
      "Successfully installed Keras-2.1.6 absl-py-0.2.2 astor-0.7.1 bleach-1.5.0 gast-0.2.0 grpcio-1.13.0 h5py-2.8.0 html5lib-0.9999999 markdown-2.6.11 protobuf-3.6.0 tensorboard-1.8.0 tensorflow-gpu-1.8.0 werkzeug-0.14.1\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.8.0 Keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\tprocessed\t\t   test.zip  train\tvalid\r\n",
      "labels.csv.zip\tsample_submission.csv.zip  tmp\t     train.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"data/train\"\n",
    "valid_folder = \"data/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE=224\n",
    "BATCH_SIZE=16\n",
    "NUM_CLASSES=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affenpinscher\t\t\titalian_greyhound\r\n",
      "afghan_hound\t\t\tjapanese_spaniel\r\n",
      "african_hunting_dog\t\tkeeshond\r\n",
      "airedale\t\t\tkelpie\r\n",
      "american_staffordshire_terrier\tkerry_blue_terrier\r\n",
      "appenzeller\t\t\tkomondor\r\n",
      "australian_terrier\t\tkuvasz\r\n",
      "basenji\t\t\t\tlabrador_retriever\r\n",
      "basset\t\t\t\tlakeland_terrier\r\n",
      "beagle\t\t\t\tleonberg\r\n",
      "bedlington_terrier\t\tlhasa\r\n",
      "bernese_mountain_dog\t\tmalamute\r\n",
      "black-and-tan_coonhound\t\tmalinois\r\n",
      "blenheim_spaniel\t\tmaltese_dog\r\n",
      "bloodhound\t\t\tmexican_hairless\r\n",
      "bluetick\t\t\tminiature_pinscher\r\n",
      "border_collie\t\t\tminiature_poodle\r\n",
      "border_terrier\t\t\tminiature_schnauzer\r\n",
      "borzoi\t\t\t\tnewfoundland\r\n",
      "boston_bull\t\t\tnorfolk_terrier\r\n",
      "bouvier_des_flandres\t\tnorwegian_elkhound\r\n",
      "boxer\t\t\t\tnorwich_terrier\r\n",
      "brabancon_griffon\t\told_english_sheepdog\r\n",
      "briard\t\t\t\totterhound\r\n",
      "brittany_spaniel\t\tpapillon\r\n",
      "bull_mastiff\t\t\tpekinese\r\n",
      "cairn\t\t\t\tpembroke\r\n",
      "cardigan\t\t\tpomeranian\r\n",
      "chesapeake_bay_retriever\tpug\r\n",
      "chihuahua\t\t\tredbone\r\n",
      "chow\t\t\t\trhodesian_ridgeback\r\n",
      "clumber\t\t\t\trottweiler\r\n",
      "cocker_spaniel\t\t\tsaint_bernard\r\n",
      "collie\t\t\t\tsaluki\r\n",
      "curly-coated_retriever\t\tsamoyed\r\n",
      "dandie_dinmont\t\t\tschipperke\r\n",
      "dhole\t\t\t\tscotch_terrier\r\n",
      "dingo\t\t\t\tscottish_deerhound\r\n",
      "doberman\t\t\tsealyham_terrier\r\n",
      "english_foxhound\t\tshetland_sheepdog\r\n",
      "english_setter\t\t\tshih-tzu\r\n",
      "english_springer\t\tsiberian_husky\r\n",
      "entlebucher\t\t\tsilky_terrier\r\n",
      "eskimo_dog\t\t\tsoft-coated_wheaten_terrier\r\n",
      "flat-coated_retriever\t\tstaffordshire_bullterrier\r\n",
      "french_bulldog\t\t\tstandard_poodle\r\n",
      "german_shepherd\t\t\tstandard_schnauzer\r\n",
      "german_short-haired_pointer\tsussex_spaniel\r\n",
      "giant_schnauzer\t\t\ttibetan_mastiff\r\n",
      "golden_retriever\t\ttibetan_terrier\r\n",
      "gordon_setter\t\t\ttoy_poodle\r\n",
      "great_dane\t\t\ttoy_terrier\r\n",
      "greater_swiss_mountain_dog\tvizsla\r\n",
      "great_pyrenees\t\t\twalker_hound\r\n",
      "groenendael\t\t\tweimaraner\r\n",
      "ibizan_hound\t\t\twelsh_springer_spaniel\r\n",
      "irish_setter\t\t\twest_highland_white_terrier\r\n",
      "irish_terrier\t\t\twhippet\r\n",
      "irish_water_spaniel\t\twire-haired_fox_terrier\r\n",
      "irish_wolfhound\t\t\tyorkshire_terrier\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2044 images belonging to 120 classes.\n",
      "Found 2044 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
    "                                   rotation_range=45,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.25,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest'\n",
    "                                  \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "train_batches = train_generator.flow_from_directory(\n",
    "    train_folder, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE,shuffle=True, seed=13,class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "valid_generator =  ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input)\n",
    "\n",
    "\n",
    "valid_batches = valid_generator.flow_from_directory(\n",
    "    valid_folder, target_size=(IMAGE_SIZE,IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2044 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = train_batches.num_classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
      "17227776/17225924 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mobile.layers[-6].output\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=mobile.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=train_generator.n//BATCH_SIZE, \n",
    "                    validation_data=validation_generator, validation_steps=3, epochs=15, verbose=2,workers=4, \n",
    "                   use_multiprocessing=True\n",
    "                   \n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dog_breed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'w') as file_handler:\n",
    "    for item in train_generator.class_indices.keys():\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/ubuntu/custom/deeplizrd/dog_breed.h5 [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 22.0 MiB/ 22.0 MiB]                                                \n",
      "Operation completed over 1 objects/22.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/ubuntu/custom/deeplizrd/dog_breed.h5 gs://np-training-public/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/custom/deeplizrd\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls /home/ubuntu/.kaggle/competitions/dog-breed-identification/train_folder/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
